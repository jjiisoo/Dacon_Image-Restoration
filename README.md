# 💻 데이콘 이미지 복원 경진대회 💻

## 💥 소개 💥
본 프로젝트는 **데이콘 이미지 복원 경진대회**에 참여하여, 손실된 이미지의 특정 영역을 복구하고 흑백 이미지에 적합한 색을 입혀 원본과 유사한 이미지로 재생성하는 알고리즘을 개발한 프로젝트이다.

### ✔️ 주요 목표
- 손실된 이미지의 특정 영역 복원
- 복원된 흑백 이미지에 적합한 색을 입히는 알고리즘 개발
- 최적의 성능을 위한 다양한 딥러닝 모델 실험

## 💥 데이터 💥

본 경진대회에서 제공된 데이터는 손실된 흑백 이미지를 복원하기 위한 학습 및 평가 데이터로 구성되어 있다.

### ✔️ 데이터 구성

| **폴더/파일**           | **설명**                                                                                      |
|-------------------------|---------------------------------------------------------------------------------------------|
| **train_input/**        | 학습용 입력 이미지 폴더 (손실된 흑백 PNG 이미지, 총 29,603장)                                 |
| **train_gt/**           | 학습용 타겟 이미지 폴더 (원본 PNG 이미지, 총 29,603장)                                        | 
| **train.csv**           | 학습 데이터 입력 이미지(`train_input`)와 타겟 이미지(`train_gt`)의 파일 경로를 매칭한 CSV 파일      |
| **test_input/**         | 평가용 입력 이미지 폴더 (손실된 흑백 PNG 이미지, 총 100장)                                   |
| **test.csv**            | 평가 데이터 입력 이미지(`test_input`)의 파일 경로 정보가 포함된 CSV 파일                      |
| **sample_submission.zip** | 추론 결과 제출 양식, ZIP 파일 내부에 복원된 PNG 이미지를 포함해야 하며, 이미지 파일명은 평가 입력 이미지 파일명과 동일해야 함 |

---

### ✔️ 데이터 특징

#### ⚪ 학습 데이터
- **입력 이미지**:
  - `train_input/` 폴더에 저장된 손실된 흑백 이미지
- **타겟 이미지**:
  - `train_gt/` 폴더에 저장된 손상되지 않은 원본 이미지
- **이미지 매칭**:
  - `train.csv`를 사용해 입력 이미지와 타겟 이미지를 매칭

#### ⚪ 평가 데이터
- **입력 이미지**:
  - `test_input/` 폴더에 저장된 손실된 흑백 이미지
- **추론 결과 제출**:
  - 평가 데이터에 대한 복원 이미지를 생성하고, `test.csv`를 참고해 입력 이미지와 동일한 파일명으로 저장

#### ⚪ 제출 형식
- 복원된 이미지는 PNG 형식으로 저장
- 이미지 파일명은 `test_input` 폴더의 입력 이미지 파일명과 동일해야 함
- 모든 복원된 이미지를 **폴더 없이 ZIP 파일로 압축**하여 제출

---

## 💥 데이터 전처리 💥

학습 데이터를 효과적으로 사용하고, 군집화를 통해 데이터를 정리하기 위해 다음과 같은 전처리 과정을 수행 **(preprocess.py)**

1. **CLIP 기반 임베딩 생성**
   - 학습 데이터(`train_gt`)의 이미지를 CLIP 모델(`geolocal/StreetCLIP`)을 사용하여 고차원 임베딩으로 변환
   - 생성된 임베딩은 L2 정규화를 통해 정규화

2. **UMAP 차원 축소**
   - 고차원 임베딩을 UMAP을 사용하여 2차원으로 축소
   - 축소된 데이터는 시각화와 군집화를 위해 활용

3. **HDBSCAN 군집화**
   - HDBSCAN 알고리즘을 활용하여 군집화를 수행
   - 군집되지 않은 데이터는 `-1`로 라벨링하여 노이즈 데이터로 처리

4. **CSV 파일 저장**
   - **학습 데이터(`train_preproc_1.csv`)**:
     - 각 이미지의 파일 이름과 군집 라벨 정보를 저장
   - **평가 데이터(`test_preproc_1.csv`)**:
     - 평가용 입력 이미지의 파일 이름을 저장

5. **결과물**
   - 전처리 과정을 통해 생성된 데이터는 모델 학습 및 평가에 활용
  
## 💥 학습 및 모델 설명 💥

학습과 모델 설계 과정에 대한 설명 **(model_train.py)**

---

### **1. 모델 구성**
- **첫 번째 모델 (Gray Mask Restoration)**
  - U-Net 아키텍처를 기반으로 손실된 흑백 이미지를 복원하는 모델
  - ResNet-34를 Encoder로 사용하며, 입력은 1채널, 출력은 1채널(복원된 흑백 이미지)

- **두 번째 모델 (Gray to Color)**:
  - U-Net 아키텍처를 기반으로 복원된 흑백 이미지를 컬러 이미지로 변환하는 모델
  - ResNet-34를 Encoder로 사용하며, 입력은 1채널(복원된 흑백 이미지), 출력은 3채널(RGB)

---

### **2. 손실 영역 처리**
- 손실된 영역을 모델 학습에 반영하기 위해 다음과 같은 데이터를 생성함
  - **손실 영역 마스크**: 이미지 내 무작위로 손실된 영역을 다각형 형태로 마스킹
  - **입력 데이터**: 손실 영역이 마스킹된 흑백 이미지
  - **타겟 데이터**: 손실되지 않은 원본 이미지

---

### **3. 학습 및 검증**
- **K-Fold Cross Validation**:
  - 데이터셋을 5개의 폴드로 나누어 모델 학습 및 검증을 진행
  - 각 폴드에서 학습 데이터와 검증 데이터를 구분하여 사용

- **손실 함수**:
  - 픽셀 손실(L1 + MSE)을 기반으로 흑백 복원 및 컬러화 결과를 최적화

- **평가 지표**:
  - **SSIM (Structural Similarity Index)**: 원본과 복원된 이미지 간의 유사성 평가
  - **Masked SSIM**: 손실된 영역에 대해 SSIM을 계산하여 복원 품질 평가
  - **히스토그램 유사도**: HSV 색 공간에서 히스토그램의 상관 계수를 사용해 유사도 평가

- **조기 중단 및 체크포인트**:
  - 조기 중단(Early Stopping)을 적용하여 3 에포크 동안 검증 성능이 향상되지 않으면 학습 종료
  - 최적의 검증 점수를 기록한 체크포인트 저장

---

### **4. 테스트 및 추론**
- **테스트 데이터**:
  - 손실된 흑백 이미지를 입력으로 받아 복원된 컬러 이미지를 생성
  - 복원된 이미지를 PNG 형식으로 저장

- **제출 파일 생성**:
  - 복원된 이미지를 평가 데이터의 파일 이름과 동일하게 저장
  - 모든 이미지를 하나의 ZIP 파일로 압축하여 제출 양식에 맞게 구성

---

### **5. 결과물**
- 복원된 이미지는 평가 데이터와 동일한 파일 구조로 저장되며 ZIP 파일로 제출
- 최종 학습된 모델을 활용한 테스트 데이터의 추론 결과를 제공

---

### **6. 기술 스택**
- **모델 아키텍처**: U-Net (ResNet-34 Backbone)
- **프레임워크**: PyTorch, PyTorch Lightning
- **손실 함수**: L1, MSE
- **평가 지표**: SSIM, Masked SSIM, Histogram Similarity
- **데이터 분할**: K-Fold Cross Validation
- **추론**: PNG 이미지 저장 및 ZIP 파일 생성

## 💥 실험 최종 결과 💥

| **구성요소**          | **값**                     |
|-------------------|----------------------------|
| **Model_1, Model_2** | U-Net                     |
| **Encoder**       | ResNet-34                  |
| **Learning rate** | 1e-4                       |
| **Batch size**    | 32                         |
| **Epoch**         | 15                         |
| **Early stopping**| 10                         |
| **Scheduler**     | ReduceLROnPlateau          |
| **Optimizer**     | AdamW                      |
| **Loss**          | L1Loss, MSELoss, SSIM      |


![TEST_002](https://github.com/user-attachments/assets/ca60ce94-4538-4cc9-a520-8fac2693b41a)
![TEST_001](https://github.com/user-attachments/assets/70a268ec-0178-4d9e-89de-edd3ae7794b9)

최종 결과의 일부 사진 (복원은 잘 됐지만 사진이 많이 흐릿하다.)

### 최종 **val_score=0.6131, private score=0.54469**로 데이콘 순위 23등으로 대회 마무리


## 💥 아쉬운 점 💥️


✔️ **학습 시간의 제한**
   - 모델의 학습 시간이 길어 학습 에포크를 15로 제한했다.
   - val_loss, val_score를 모니터링한 결과 더 많은 에포크로 학습을 진행했다면 성능이 더 향상될 가능성이 있었다.
   - 최종 결과 외 model1 : Unet + resnet34, model2 : FPN + efficientnet-b4 에서 높은 에포크를 설정해 실험 진행했다면 좋은 결과를 얻을 가능성이 높았다.
   - 과적합 발생 전 모델 학습을 중단시켜 학습을 다 하지 못한 채 평가에 사용했다.

✔️ **추가 최적화 부족**
   - 하이퍼파라미터 최적화(Search)를 충분히 진행하지 못했다.
   - 스케줄러와 학습률의 세부 조정이 더 필요했을 수 있다.


## 💥 후속 연구 💥

### 아쉬운 점들을 개선하기 위한 후속 연구 계획
  - 분산 학습 기법을 도입하여 학습 시간 단축
  - 에포크 수 늘려 과적합 발생 전까지 모델 학습
  - 다양한 평가지표 사용


  



